# -*- coding: utf-8 -*-
"""Submission-1-BPML-Dicoding-v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVdjlXMV5LDlRiK8IfBkL0YxdVfh349p

**Dataset Source**  
https://www.kaggle.com/datasets/rajatrc1705/youtube-videos-dataset

Meng-*import library* python yang dibutuhkan.
"""

# Commented out IPython magic to ensure Python compatibility.
# dataframe
import pandas as pd

# split data
from sklearn.model_selection import train_test_split

# preprocessing and layer
import tensorflow as tf
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.layers import LSTM, Dense, Embedding, Dropout
from keras.models import Sequential

# plotting
# %load_ext tensorboard

"""Membaca dataset."""

df = pd.read_csv('youtube.csv')

df

"""Mengecek jumlah value tiap category."""

df['category'].value_counts()

"""Menerapkan proses one-hot-encoding dan membuat dataframe baru."""

category = pd.get_dummies(df.category)
df_new = pd.concat([df, category], axis=1)
df_new =  df_new.drop(columns='category')

df_new

"""Mengubah nilai-nilai pada dataframe ke dalam tipe data numpy array menggunakan atribut values agar data dapat diproses oleh model."""

title = df_new['title'].values
label = df_new[['art_music', 'food', 'history', 'travel']].values

"""Membagi dataset menjadi train set dan validation set dengan ukuran masing-masing 80% dan 20%."""

title_train, title_test, label_train, label_test = train_test_split(title, label, test_size=0.2)

"""Mengubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer. Setelahnya, konversi setiap sampel menjadi sequence."""

# Techniques Data
max_words = 2000

tokenizer = Tokenizer(num_words=max_words, oov_token='x')

tokenizer.fit_on_texts(title_train)
sequences_train = tokenizer.texts_to_sequences(title_train)
sequences_test = tokenizer.texts_to_sequences(title_test)

padded_train = pad_sequences(sequences_train) 
padded_test = pad_sequences(sequences_test)

"""Membangun model Sequential dengan Embedding dan LSTM."""

model = tf.keras.Sequential([
                    Embedding(input_dim=5000, output_dim=32),
                    LSTM(64),
                    Dense(256, activation='relu'),
                    Dropout(0.5),
                    Dense(128, activation='relu'),
                    Dropout(0.5),
                    Dense(64, activation='relu'),
                    Dropout(0.5),
                    Dense(4, activation='softmax')
                    ])

"""Menentukan optimizer dan loss function dari model. Untuk masalah klasifikasi multi kelas, menggunakan loss ‘categorical_crossentropy’."""

model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

"""Latih model dengan model.fit dan menyimpannya ke dalam variabel history guna memudahkan proses *plotting*."""

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir="logs")

num_epochs = 30
history = model.fit(padded_train, 
                    label_train, 
                    epochs=num_epochs, 
                    validation_data=(padded_test, label_test), 
                    verbose=2, 
                    callbacks = [tensorboard_callback])

"""Menguji akurasi prediksi model pada data uji"""

model.evaluate(padded_train, label_train)

"""Memvisualisasikan *history* model melalui plotting grafik accuracy dan loss guna mempermudah evaluasi model secara grafik dengan menggunakan TensorBoard."""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs