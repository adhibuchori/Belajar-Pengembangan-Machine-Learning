# -*- coding: utf-8 -*-
"""Submission-2-BPML-Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oMgnjiYXmtbW9PagYmzJd-mzFL1X8i5T

**Data Source**  
https://www.kaggle.com/code/msripooja/hourly-energy-consumption-time-series-rnn-lstm/notebook

Meng-*import library* python yang dibutuhkan.
"""

# Dataframe
import pandas as pd
import numpy as np

# Split Data
from sklearn.model_selection import train_test_split

# Preprocessing dan Layer
import sklearn.preprocessing
import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Bidirectional, Dropout
from sklearn.metrics import r2_score

# Visualisasi Plot
import matplotlib.pyplot as plt
from plotly import graph_objs as go

"""Membaca dan menampilkan dataset."""

df = pd.read_csv('AEP_hourly.csv')
df

"""Melakukan pengecekan keberadaan *missing values* pada dataset"""

df.isnull().sum()

"""Melakukan proses normalisasi terhadap dataset dengan menggunakan fungsi `MinMaxScaler()` guna mengubah nilai-nilai dari sebuah fitur ke dalam skala yang sama."""

def normalize_data(df):
    scaler = sklearn.preprocessing.MinMaxScaler()
    df['AEP_MW']=scaler.fit_transform(df['AEP_MW'].values.reshape(-1,1))
    return df

df_norm = normalize_data(df)
df_norm.shape

"""Melakukan *plotting* grafik terhadap dataframe setelah normalisasi."""

df_norm.plot(figsize=(16,4),legend=True)
plt.title('American Electric Power (AEP) estimated energy consumption in Megawatts (MW) hourly power consumption data after Normalization')
plt.show()

"""Melakukan pengecekan bentuk data."""

df_norm.shape

"""Mengubah nilai-nilai pada dataframe ke dalam tipe data numpy array menggunakan atribut values agar data dapat diproses oleh model."""

dates = df['Datetime'].values
aep = df['AEP_MW'].values

"""Melakukan pengecekan tipe data masing-masing kolom pada dataframe."""

df.dtypes

"""Membagi dataset menjadi train set dan validation set dengan ukuran masing-masing 80% dan 20%."""

x_train, x_valid, y_train, y_valid = train_test_split(aep, dates, train_size=0.8, test_size=0.2, shuffle=False )

print('Total Data Train : ',len(x_train))
print('Total Data Validation : ',len(x_valid))

"""Membuat fungsi `windowed_dataset` untuk menerima sebuah series/atribut kita yang telah di konversi menjadi tipe numpy, lalu mengembalikan label dan atribut dari dataset dalam bentuk batch."""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

"""Membuat arsitektur model dengan menggunakan gunakan 2 buah layer `Bidirectional LSTM` yang dilengkapi dengan `dropout` guna mencegah *overfitting*. """

train_set = windowed_dataset(x_train, window_size=60, batch_size=200, shuffle_buffer=1000)
val_set = windowed_dataset(x_valid, window_size=60, batch_size=200, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
                                    Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),
                                    Bidirectional(tf.keras.layers.LSTM(60, dropout=0.2)),
                                    Dense(16, activation="relu"),
                                    Dropout(0.2),
                                    Dense(8, activation="relu"),
                                    Dense(1),
])

"""Melakukan pengecekan nilai MAE dari model < 10% skala data."""

minMae = (df['AEP_MW'].max() - df['AEP_MW'].min()) * 10/100
print(minMae)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < minMae and logs.get('val_mae') < minMae):
      print("\MAE dari model < 10% skala data")
      self.model.stop_training = True
callbacks = myCallback()

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)

model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

history = model.fit(train_set, epochs=100, validation_data=val_set, callbacks=[callbacks])

"""Memvisualisasikan *history* model melalui plotting grafik mae dan loss guna mempermudah evaluasi model secara grafik dengan menggunakan *library* python `Matplotlib`."""

figure = plt.figure(figsize = (15, 5))

figure.add_subplot(1, 2, 1)
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Mae and Validation Mae Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'lower right')

figure.add_subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'upper right')

plt.show()