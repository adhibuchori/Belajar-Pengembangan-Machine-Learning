# -*- coding: utf-8 -*-
"""FinalProject_BPML_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uui7NfrPa4-2mbWkCJTIbrPrjqWo4vIJ

# Required Libraries
"""

# Directory
import os, zipfile, shutil

# Preprocessing and Layer
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense
from keras_preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import MaxPooling2D, Dense, Dropout, Conv2D

# Plotting
import matplotlib.pyplot as plt

"""# Dataset Preparation

**Dataset Source**  
https://www.kaggle.com/datasets/alessiocorrado99/animals10

Install kaggle package.
"""

!pip install -q kaggle

"""Upload kaggle.json"""

from google.colab import files
files.upload()

"""Preparing the directory."""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/

"""Download dataset."""

!kaggle datasets download -d viratkothari/animal10

"""Extract the zip file."""

local_zip = '/content/animal10.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""Defines the directory name for the train data and validation data."""

main_dir = os.path.join('/content/Animals-10')
print(os.listdir(main_dir))

"""Delete unneeded folders."""

ignore_dir = ['elephant', 'cat', 'sheep', 'cow', 'squirrel', 'butterfly', 'horse']

for dir in ignore_dir:
  path = os.path.join(main_dir, dir)
  shutil.rmtree(path)

print(os.listdir(main_dir))

from PIL import Image
samples = 0

for x in os.listdir(main_dir):
  dir = os.path.join('/content/Animals-10', x)
  y = len(os.listdir(dir))
  print(x+' :', y)
  samples = samples + y
  
  image_name = os.listdir(dir)
  for z in range(3):
    image_path = os.path.join(dir, image_name[z])
    image = Image.open(image_path)
    print(image.size)
  print()


print('Total Sample : ', samples)

"""# Split Dataset

Splitting the dataset into train sets and validation sets with sizes of 80% and 20%, respectively.
"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range = 0.2,
    zoom_range = 0.2,
    fill_mode = 'nearest',
    validation_split = 0.2)

train_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150, 150),
    batch_size=128,
    class_mode='categorical',
    subset='training')
 
validation_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150, 150),
    batch_size=128,
    class_mode='categorical',
    subset='validation')

"""# Callback"""

class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') and logs.get('val_accuracy') > 0.92):
      print("\n Sorry, data training was stopped because the accuracy rate was above 92%!")
      self.model.stop_training = True

callbacks = Callback()

"""# Prepare CNN Model Architecture

"""

model = Sequential()

model.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3))),
model.add(MaxPooling2D(2, 2)),

model.add(Conv2D(64, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Conv2D(128, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Conv2D(128, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Flatten()),

model.add(Dense(512, activation='relu')),
model.add(Dense(3, activation='softmax')),

model.summary()

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(
    train_generator,
    epochs=50,
    validation_data=validation_generator,
    verbose=2,
    callbacks=[callbacks])

"""# Plotting"""

figure = plt.figure(figsize = (15, 5))

figure.add_subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'lower right')

figure.add_subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'upper right')

"""# TF-Lite Model Preparation

Convert the Model to TF-Lite
"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

"""Saving the TF-Lite Model"""

# Menyimpan TFlite Model
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
